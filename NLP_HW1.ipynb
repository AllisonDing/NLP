{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUg1Gtc10NVgcKSyksIX+6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AllisonDing/Natural-Language-Processing/blob/main/NLP_HW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNsO3Qz1vRZA"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "-5E8y_wA-uZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stop_words.update(['is', \"n't\"])  # Add 'is' and 'n't' to stopwords\n",
        "stemmer = PorterStemmer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stBq-W_v_BYu",
        "outputId": "34aea779-fdc2-4af1-dc6d-065fec6c395e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_sentence(sentence, to_stem=False, to_remove_stop_words=False):\n",
        "  # Tokenize the sentence\n",
        "  tokens = word_tokenize(sentence.lower())\n",
        "\n",
        "  # Remove stop words if required\n",
        "  if to_remove_stop_words:\n",
        "      tokens = [token for token in tokens if token not in stop_words and token.isalpha()]\n",
        "\n",
        "  # Apply stemming if required\n",
        "  if to_stem:\n",
        "      tokens = [stemmer.stem(token) for token in tokens]\n",
        "\n",
        "  # Prepare text again after processing\n",
        "  processed_text = ' '.join(tokens)\n",
        "  return processed_text"
      ],
      "metadata": {
        "id": "uR4MeL2nB_PB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_similarity(A, B):\n",
        "  dot_product = np.dot(A, B)\n",
        "  norm_A = np.linalg.norm(A)\n",
        "  norm_B = np.linalg.norm(B)\n",
        "  return dot_product/(norm_A*norm_B)"
      ],
      "metadata": {
        "id": "5GcONa01PTfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_sentences(sentence1, sentence2, encoding_type='one-hot'):\n",
        "  # Choose the vectorizer based on encoding_type\n",
        "  if encoding_type == 'one-hot':\n",
        "    vectorizer = CountVectorizer(binary=True)\n",
        "  elif encoding_type == 'bag of words':\n",
        "    vectorizer = CountVectorizer(binary=False)\n",
        "  elif encoding_type == 'tf':\n",
        "    vectorizer = TfidfVectorizer(use_idf=False, norm = 'l1')  # TF (term frequency) with normalization\n",
        "  elif encoding_type == 'tfXidf':\n",
        "    vectorizer = TfidfVectorizer(use_idf=True, norm = 'l1')  # TF-IDF\n",
        "\n",
        "  # fit the vectorizer to both sentences to ensure the same feature space\n",
        "  vectors = vectorizer.fit_transform([sentence1, sentence2]).toarray()\n",
        "  print(vectors)\n",
        "\n",
        "  # calculate cosine similarity\n",
        "  similarity = cosine_similarity(vectors[0], vectors[1])\n",
        "  return similarity"
      ],
      "metadata": {
        "id": "q2flrHJrFiVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence1 = \"The engineer spoke about the importance of innovation and sustainability in building design.\"\n",
        "sentence2 = \"The engineer has not spoken about the importance of innovation and sustainability not in building design.\"\n",
        "compare_sentences(sentence1, sentence2, encoding_type='tfXidf')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBgxnmyEW0gu",
        "outputId": "f5b444e1-dbad-4256-8e60-db9dc34e8ed4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.07459644 0.07459644 0.07459644 0.07459644 0.07459644 0.\n",
            "  0.07459644 0.07459644 0.07459644 0.         0.07459644 0.1048427\n",
            "  0.         0.07459644 0.14919288]\n",
            " [0.0567477  0.0567477  0.0567477  0.0567477  0.0567477  0.07975691\n",
            "  0.0567477  0.0567477  0.0567477  0.15951382 0.0567477  0.\n",
            "  0.07975691 0.0567477  0.11349539]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6888998213683907"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 stop-word removal increases recall\n",
        "# set to_stem to False; encoding to one-hot\n",
        "sentence1 = \"The engineer spoke about the importance of innovation and sustainability in building design.\"\n",
        "sentence2 = \"The engineer has not spoken about the importance of innovation and sustainability not in building design.\"\n",
        "processed_sentence1 = encode_sentence(sentence1, to_stem=False, to_remove_stop_words=True)\n",
        "processed_sentence2 = encode_sentence(sentence2, to_stem=False, to_remove_stop_words=True)\n",
        "similarity_score_before = compare_sentences(sentence1, sentence2, encoding_type='one-hot')\n",
        "similarity_score_after = compare_sentences(processed_sentence1, processed_sentence2, encoding_type='one-hot')\n",
        "print(f\"Sentence1: {sentence1}\")\n",
        "print(f\"Sentence2: {sentence2}\")\n",
        "print(f\"Before Similarity Score: {similarity_score_before}\")\n",
        "print(\"Stop Words Removed\")\n",
        "print(f\"Processed Sentence1: {processed_sentence1}\")\n",
        "print(f\"Processed Sentence2: {processed_sentence2}\")\n",
        "print(f\"After Similarity Score: {similarity_score_after}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQFqDEQY8MwI",
        "outputId": "72cc50b7-f0cb-4d27-d8cc-5c0230bd27d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence1: The engineer spoke about the importance of innovation and sustainability in building design.\n",
            "Sentence2: The engineer has not spoken about the importance of innovation and sustainability not in building design.\n",
            "Before Similarity Score: 0.8486684247915056\n",
            "Stop Words Removed\n",
            "Processed Sentence1: engineer spoke importance innovation sustainability building design\n",
            "Processed Sentence2: engineer spoken importance innovation sustainability building design\n",
            "After Similarity Score: 0.857142857142857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 stop-word removal increases recall\n",
        "# set to_stem to False; encoding to one-hot\n",
        "sentence1 = \"A frog is jumping quickly onto the table\"\n",
        "sentence2 = \"The frog jumps quick over on the table\"\n",
        "processed_sentence1 = encode_sentence(sentence1, to_stem=False, to_remove_stop_words=True)\n",
        "processed_sentence2 = encode_sentence(sentence2, to_stem=False, to_remove_stop_words=True)\n",
        "similarity_score_before = compare_sentences(sentence1, sentence2, encoding_type='one-hot')\n",
        "similarity_score_after = compare_sentences(processed_sentence1, processed_sentence2, encoding_type='one-hot')\n",
        "print(f\"Sentence1: {sentence1}\")\n",
        "print(f\"Sentence2: {sentence2}\")\n",
        "print(f\"Before Similarity Score: {similarity_score_before}\")\n",
        "print(\"Stop Words Removed\")\n",
        "print(f\"Processed Sentence1: {processed_sentence1}\")\n",
        "print(f\"Processed Sentence2: {processed_sentence2}\")\n",
        "print(f\"After Similarity Score: {similarity_score_after}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOT4fyjPGlFm",
        "outputId": "e62eaaf1-a7da-46aa-faf4-6ec7f594b27c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence1: A frog is jumping quickly onto the table\n",
            "Sentence2: The frog jumps quick over on the table\n",
            "Before Similarity Score: 0.4285714285714285\n",
            "Stop Words Removed\n",
            "Processed Sentence1: frog jumping quickly onto table\n",
            "Processed Sentence2: frog jumps quick table\n",
            "After Similarity Score: 0.4472135954999579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 stop-word removal decreases precision\n",
        "# set to_stem to False; encoding to one-hot\n",
        "sentence1 = \"The actor saw the man with the telescope.\"\n",
        "sentence2 = \"The actor has not seen the man with the telescope.\"\n",
        "processed_sentence1 = encode_sentence(sentence1, to_stem=False, to_remove_stop_words=True)\n",
        "processed_sentence2 = encode_sentence(sentence2, to_stem=False, to_remove_stop_words=True)\n",
        "similarity_score_before = compare_sentences(sentence1, sentence2, encoding_type='one-hot')\n",
        "similarity_score_after = compare_sentences(processed_sentence1, processed_sentence2, encoding_type='one-hot')\n",
        "print(f\"Sentence1: {sentence1}\")\n",
        "print(f\"Sentence2: {sentence2}\")\n",
        "print(f\"Before Similarity Score: {similarity_score_before}\")\n",
        "print(\"Stop Word Removed\")\n",
        "print(f\"Processed Sentence1: {processed_sentence1}\")\n",
        "print(f\"Processed Sentence2: {processed_sentence2}\")\n",
        "print(f\"After Similarity Score: {similarity_score_after}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6E7U9dQOVmZ2",
        "outputId": "d4ddcb10-c1e9-4072-8a18-ac97bc475714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence1: The actor saw the man with the telescope.\n",
            "Sentence2: The actor has not seen the man with the telescope.\n",
            "Before Similarity Score: 0.7216878364870323\n",
            "Stop Word Removed\n",
            "Processed Sentence1: actor saw man telescope\n",
            "Processed Sentence2: actor seen man telescope\n",
            "After Similarity Score: 0.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 stop-word removal decreases precision\n",
        "# set to_stem to False; encoding to one-hot\n",
        "sentence1 = \"The cat has not run on the court.\"\n",
        "sentence2 = \"A cat is running on the court.\"\n",
        "processed_sentence1 = encode_sentence(sentence1, to_stem=False, to_remove_stop_words=True)\n",
        "processed_sentence2 = encode_sentence(sentence2, to_stem=False, to_remove_stop_words=True)\n",
        "similarity_score_before = compare_sentences(sentence1, sentence2, encoding_type='one-hot')\n",
        "similarity_score_after = compare_sentences(processed_sentence1, processed_sentence2, encoding_type='one-hot')\n",
        "print(f\"Sentence1: {sentence1}\")\n",
        "print(f\"Sentence2: {sentence2}\")\n",
        "print(f\"Before Similarity Score: {similarity_score_before}\")\n",
        "print(\"Stop Word Removed\")\n",
        "print(f\"Processed Sentence1: {processed_sentence1}\")\n",
        "print(f\"Processed Sentence2: {processed_sentence2}\")\n",
        "print(f\"After Similarity Score: {similarity_score_after}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIkm8_6jHMgx",
        "outputId": "f0016dce-10c2-4b10-8517-f39fcac1dee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence1: The cat has not run on the court.\n",
            "Sentence2: A cat is running on the court.\n",
            "Before Similarity Score: 0.6172133998483676\n",
            "Stop Word Removed\n",
            "Processed Sentence1: cat run court\n",
            "Processed Sentence2: cat running court\n",
            "After Similarity Score: 0.6666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3 stemming increases recall\n",
        "# set stop_word removal to False; encoding to one-hot\n",
        "sentence1 = \"The company is expanding rapidly due to an increase in demand for its products.\"\n",
        "sentence2 = \"The corporation has decided to expand its operations due to rising demands.\"\n",
        "processed_sentence1 = encode_sentence(sentence1, to_stem=True, to_remove_stop_words=False)\n",
        "processed_sentence2 = encode_sentence(sentence2, to_stem=True, to_remove_stop_words=False)\n",
        "similarity_score_before = compare_sentences(sentence1, sentence2, encoding_type='one-hot')\n",
        "similarity_score_after = compare_sentences(processed_sentence1, processed_sentence2, encoding_type='one-hot')\n",
        "print(f\"Sentence1: {sentence1}\")\n",
        "print(f\"Sentence2: {sentence2}\")\n",
        "print(f\"Before Similarity Score: {similarity_score_before}\")\n",
        "print(\"Stem Word\")\n",
        "print(f\"Processed Sentence1: {processed_sentence1}\")\n",
        "print(f\"Processed Sentence2: {processed_sentence2}\")\n",
        "print(f\"After Similarity Score: {similarity_score_after}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2p9uW_neXrgk",
        "outputId": "6c2355b5-5ce0-4391-fba3-c22c00cede5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence1: The company is expanding rapidly due to an increase in demand for its products.\n",
            "Sentence2: The corporation has decided to expand its operations due to rising demands.\n",
            "Before Similarity Score: 0.3223291856101521\n",
            "Stem Word\n",
            "Processed Sentence1: the compani is expand rapidli due to an increas in demand for it product .\n",
            "Processed Sentence2: the corpor ha decid to expand it oper due to rise demand .\n",
            "After Similarity Score: 0.48349377841522817\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3 stemming increases recall\n",
        "# set stop_word removal to False; encoding to one-hot\n",
        "sentence1 = \"Many companies are integrating advanced artificial intelligence into daily operations.\"\n",
        "sentence2 = \"Several businesses have integrated advanced AI technologies for daily tasks.\"\n",
        "processed_sentence1 = encode_sentence(sentence1, to_stem=True, to_remove_stop_words=False)\n",
        "processed_sentence2 = encode_sentence(sentence2, to_stem=True, to_remove_stop_words=False)\n",
        "similarity_score_before = compare_sentences(sentence1, sentence2, encoding_type='one-hot')\n",
        "similarity_score_after = compare_sentences(processed_sentence1, processed_sentence2, encoding_type='one-hot')\n",
        "print(f\"Sentence1: {sentence1}\")\n",
        "print(f\"Sentence2: {sentence2}\")\n",
        "print(f\"Before Similarity Score: {similarity_score_before}\")\n",
        "print(\"Stem Word\")\n",
        "print(f\"Processed Sentence1: {processed_sentence1}\")\n",
        "print(f\"Processed Sentence2: {processed_sentence2}\")\n",
        "print(f\"After Similarity Score: {similarity_score_after}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cG9PgrPJH_OD",
        "outputId": "7b1b9d87-4eeb-43a8-dc02-337e63eee698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence1: Many companies are integrating advanced artificial intelligence into daily operations.\n",
            "Sentence2: Several businesses have integrated advanced AI technologies for daily tasks.\n",
            "Before Similarity Score: 0.19999999999999996\n",
            "Stem Word\n",
            "Processed Sentence1: mani compani are integr advanc artifici intellig into daili oper .\n",
            "Processed Sentence2: sever busi have integr advanc ai technolog for daili task .\n",
            "After Similarity Score: 0.29999999999999993\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4 stemming decreases precision\n",
        "# set stop_word removal to False; encoding to one-hot\n",
        "sentence1 = \"The developer creates innovative software solutions to optimize various business processes.\"\n",
        "sentence2 = \"Innovatively created software by developers optimizing business process solutions has shown significant improvements.\"\n",
        "processed_sentence1 = encode_sentence(sentence1, to_stem=True, to_remove_stop_words=False)\n",
        "processed_sentence2 = encode_sentence(sentence2, to_stem=True, to_remove_stop_words=False)\n",
        "similarity_score_before = compare_sentences(sentence1, sentence2, encoding_type='one-hot')\n",
        "similarity_score_after = compare_sentences(processed_sentence1, processed_sentence2, encoding_type='one-hot')\n",
        "print(f\"Sentence1: {sentence1}\")\n",
        "print(f\"Sentence2: {sentence2}\")\n",
        "print(f\"Before Similarity Score: {similarity_score_before}\")\n",
        "print(\"Stem Word\")\n",
        "print(f\"Processed Sentence1: {processed_sentence1}\")\n",
        "print(f\"Processed Sentence2: {processed_sentence2}\")\n",
        "print(f\"After Similarity Score: {similarity_score_after}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itCoRr9EX_0W",
        "outputId": "3f1e951b-1d99-4aab-97a0-17e3e0437707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence1: The developer creates innovative software solutions to optimize various business processes.\n",
            "Sentence2: Innovatively created software by developers optimizing business process solutions has shown significant improvements.\n",
            "Before Similarity Score: 0.25087260300212727\n",
            "Stem Word\n",
            "Processed Sentence1: the develop creat innov softwar solut to optim variou busi process .\n",
            "Processed Sentence2: innov creat softwar by develop optim busi process solut ha shown signific improv .\n",
            "After Similarity Score: 0.6689936080056726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4 stemming decreases precision\n",
        "# set stop_word removal to False; encoding to one-hot\n",
        "sentence1 = \"Public health officials are urging people to get vaccinated against the flu.\"\n",
        "sentence2 = \"National Health authorities have urged flu vaccinations for the public.\"\n",
        "processed_sentence1 = encode_sentence(sentence1, to_stem=True, to_remove_stop_words=False)\n",
        "processed_sentence2 = encode_sentence(sentence2, to_stem=True, to_remove_stop_words=False)\n",
        "similarity_score_before = compare_sentences(sentence1, sentence2, encoding_type='one-hot')\n",
        "similarity_score_after = compare_sentences(processed_sentence1, processed_sentence2, encoding_type='one-hot')\n",
        "print(f\"Sentence1: {sentence1}\")\n",
        "print(f\"Sentence2: {sentence2}\")\n",
        "print(f\"Before Similarity Score: {similarity_score_before}\")\n",
        "print(\"Stem Word\")\n",
        "print(f\"Processed Sentence1: {processed_sentence1}\")\n",
        "print(f\"Processed Sentence2: {processed_sentence2}\")\n",
        "print(f\"After Similarity Score: {similarity_score_after}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Me1mDv0hIyzw",
        "outputId": "c3063370-6910-4eb7-cf70-5bd252727523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence1: Public health officials are urging people to get vaccinated against the flu.\n",
            "Sentence2: National Health authorities have urged flu vaccinations for the public.\n",
            "Before Similarity Score: 0.3651483716701107\n",
            "Stem Word\n",
            "Processed Sentence1: public health offici are urg peopl to get vaccin against the flu .\n",
            "Processed Sentence2: nation health author have urg flu vaccin for the public .\n",
            "After Similarity Score: 0.5477225575051661\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5 bag of words has higher precision than one-hot encoding\n",
        "# set both to_stem and stop_word removal to False\n",
        "sentence1 = \"A brown frog jumps quickly on the table.\"\n",
        "sentence2 = \"The brown frog is jumping quick onto the table.\"\n",
        "processed_sentence1 = encode_sentence(sentence1, to_stem=False, to_remove_stop_words=False)\n",
        "processed_sentence2 = encode_sentence(sentence2, to_stem=False, to_remove_stop_words=False)\n",
        "similarity_score_before = compare_sentences(processed_sentence1, processed_sentence2, encoding_type='one-hot')\n",
        "similarity_score_after = compare_sentences(processed_sentence1, processed_sentence2, encoding_type='bag of words')\n",
        "print(f\"Processed Sentence1: {processed_sentence1}\")\n",
        "print(f\"Processed Sentence2: {processed_sentence2}\")\n",
        "print(f\"Similarity Score with One-Hot Encoder: {similarity_score_before}\")\n",
        "print(f\"Similarity Score with Bag of Words: {similarity_score_after}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Jqi69VjYSfE",
        "outputId": "10061c8d-c588-41b5-e9d8-05d4005f33e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed Sentence1: a brown frog jumps quickly on the table .\n",
            "Processed Sentence2: the brown frog is jumping quick onto the table .\n",
            "Similarity Score with One-Hot Encoder: 0.5345224838248487\n",
            "Similarity Score with Bag of Words: 0.5698028822981898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5 bag of words has higher precision than one-hot encoding\n",
        "# set both to_stem and stop_word removal to False\n",
        "sentence1 = \"The student read the book and the book was very interesting and informative.\"\n",
        "sentence2 = \"The book was read by the student and found to be interesting and informative.\"\n",
        "processed_sentence1 = encode_sentence(sentence1, to_stem=False, to_remove_stop_words=False)\n",
        "processed_sentence2 = encode_sentence(sentence2, to_stem=False, to_remove_stop_words=False)\n",
        "similarity_score_before = compare_sentences(processed_sentence1, processed_sentence2, encoding_type='one-hot')\n",
        "similarity_score_after = compare_sentences(processed_sentence1, processed_sentence2, encoding_type='bag of words')\n",
        "print(f\"Processed Sentence1: {processed_sentence1}\")\n",
        "print(f\"Processed Sentence2: {processed_sentence2}\")\n",
        "print(f\"Similarity Score with One-Hot Encoder: {similarity_score_before}\")\n",
        "print(f\"Similarity Score with Bag of Words: {similarity_score_after}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0B0j4YnrJfoc",
        "outputId": "cd0be614-9fbe-4af3-b383-c9e5b81d1619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed Sentence1: the student read the book and the book was very interesting and informative .\n",
            "Processed Sentence2: the book was read by the student and found to be interesting and informative .\n",
            "Similarity Score with One-Hot Encoder: 0.769800358919501\n",
            "Similarity Score with Bag of Words: 0.8355044182110839\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6 tf has higher precision than bag of words\n",
        "# set both to_stem and stop_word removal to False\n",
        "sentence1 = \"A brown frog jumps quickly on the table.\"\n",
        "sentence2 = \"The brown frog is jumping quick onto the table.\"\n",
        "processed_sentence1 = encode_sentence(sentence1, to_stem=False, to_remove_stop_words=False)\n",
        "processed_sentence2 = encode_sentence(sentence2, to_stem=False, to_remove_stop_words=False)\n",
        "similarity_score_before = compare_sentences(processed_sentence1, processed_sentence2, encoding_type='bag of words')\n",
        "similarity_score_after = compare_sentences(processed_sentence1, processed_sentence2, encoding_type='tf')\n",
        "print(f\"Processed Sentence1: {processed_sentence1}\")\n",
        "print(f\"Processed Sentence2: {processed_sentence2}\")\n",
        "print(f\"Similarity Score with Bag of Words: {similarity_score_before}\")\n",
        "print(f\"Similarity Score with tf: {similarity_score_after}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6Yc5Z4827hs",
        "outputId": "214d2f3c-f6f6-47ac-b8a3-5941e93014dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed Sentence1: a brown frog jumps quickly on the table .\n",
            "Processed Sentence2: the brown frog is jumping quick onto the table .\n",
            "Similarity Score with Bag of Words: 0.5698028822981898\n",
            "Similarity Score with tf: 0.5698028822981899\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6 tf has higher precision than bag of words\n",
        "# set both to_stem and stop_word removal to False\n",
        "sentence1 = \"A new tech startup launched a revolutionary software product that is designed to enhance productivity and collaboration.\"\n",
        "sentence2 = \"The new software product was launched by a tech startup which is designed to improve productivity and teamwork.\"\n",
        "processed_sentence1 = encode_sentence(sentence1, to_stem=False, to_remove_stop_words=False)\n",
        "processed_sentence2 = encode_sentence(sentence2, to_stem=False, to_remove_stop_words=False)\n",
        "similarity_score_before = compare_sentences(processed_sentence1, processed_sentence2, encoding_type='bag of words')\n",
        "similarity_score_after = compare_sentences(processed_sentence1, processed_sentence2, encoding_type='tf')\n",
        "print(f\"Processed Sentence1: {processed_sentence1}\")\n",
        "print(f\"Processed Sentence2: {processed_sentence2}\")\n",
        "print(f\"Similarity Score with Bag of Words: {similarity_score_before}\")\n",
        "print(f\"Similarity Score with tf: {similarity_score_after}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZPrIkBZQ2zD",
        "outputId": "92a355bf-fdf3-4afb-e0cc-06b82f2cb502"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed Sentence1: a new tech startup launched a revolutionary software product that is designed to enhance productivity and collaboration .\n",
            "Processed Sentence2: the new software product was launched by a tech startup which is designed to improve productivity and teamwork .\n",
            "Similarity Score with Bag of Words: 0.6888467201936644\n",
            "Similarity Score with tf: 0.6888467201936646\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7 tfXidf has higher precision than tf\n",
        "# set both to_stem and stop_word removal to False\n",
        "sentence1 = \"A brown frog jumps quickly on the table.\"\n",
        "sentence2 = \"The brown frog is jumping quick onto the table.\"\n",
        "processed_sentence1 = encode_sentence(sentence1, to_stem=False, to_remove_stop_words=False)\n",
        "processed_sentence2 = encode_sentence(sentence2, to_stem=False, to_remove_stop_words=False)\n",
        "similarity_score_before = compare_sentences(processed_sentence1, processed_sentence2, encoding_type='tf')\n",
        "similarity_score_after = compare_sentences(processed_sentence1, processed_sentence2, encoding_type='tfXidf')\n",
        "print(f\"Processed Sentence1: {processed_sentence1}\")\n",
        "print(f\"Processed Sentence2: {processed_sentence2}\")\n",
        "print(f\"Similarity Score with tf: {similarity_score_before}\")\n",
        "print(f\"Similarity Score with tfXidf: {similarity_score_after}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxpKCnkl4vdI",
        "outputId": "5f2e91ab-7059-4d6c-f610-5ce95fe5d8e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed Sentence1: a brown frog\n",
            "Processed Sentence2: the brown frog\n",
            "Similarity Score with tf: 0.8164965809277261\n",
            "Similarity Score with tfXidf: 0.7092972666062739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7 tfXidf has higher precision than tf\n",
        "# set both to_stem and stop_word removal to False\n",
        "sentence1 = \"The cat enjoys sitting on the mat very much.\"\n",
        "sentence2 = \"A cat likes to sit on a mat a lot.\"\n",
        "processed_sentence1 = encode_sentence(sentence1, to_stem=False, to_remove_stop_words=False)\n",
        "processed_sentence2 = encode_sentence(sentence2, to_stem=False, to_remove_stop_words=False)\n",
        "similarity_score_before = compare_sentences(processed_sentence1, processed_sentence2, encoding_type='tf')\n",
        "similarity_score_after = compare_sentences(processed_sentence1, processed_sentence2, encoding_type='tfXidf')\n",
        "print(f\"Processed Sentence1: {processed_sentence1}\")\n",
        "print(f\"Processed Sentence2: {processed_sentence2}\")\n",
        "print(f\"Similarity Score with tf: {similarity_score_before}\")\n",
        "print(f\"Similarity Score with tfXidf: {similarity_score_after}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQud4y385VfI",
        "outputId": "8165f117-a2a8-4a1d-82f2-8f0c84cccb47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed Sentence1: the cat enjoys sitting on the mat very much .\n",
            "Processed Sentence2: a cat likes to sit on a mat a lot .\n",
            "Similarity Score with tf: 0.3418817293789139\n",
            "Similarity Score with tfXidf: 0.2095424038071012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternative approach to compute tf, idf, and tfXidf from a suitable corpus\n",
        "\n",
        "import math\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "def calculate_tf(document):\n",
        "    \"\"\"\n",
        "    Calculate TF (Term Frequency) for each word in a single document.\n",
        "\n",
        "    Args:\n",
        "    document (list of str): A list of words representing a document.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary where keys are words and values are their TF scores.\n",
        "    \"\"\"\n",
        "\n",
        "    # Total number of words in the document\n",
        "    total_words = len(document)\n",
        "    # Frequency of each word in the document\n",
        "    word_freq = Counter(document)\n",
        "    # Calculate TF for each word\n",
        "    tf_scores = {word: freq / total_words for word, freq in word_freq.items()}\n",
        "    return tf_scores\n",
        "\n",
        "def calculate_idf(documents):\n",
        "    \"\"\"\n",
        "    Calculate IDF (Inverse Document Frequency) for words in a collection of documents.\n",
        "\n",
        "    Args:\n",
        "    documents (list of list of str): Each element is a list of words representing a document.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary where keys are words and values are their IDF scores.\n",
        "    \"\"\"\n",
        "    N = len(documents)\n",
        "    word_doc_count = defaultdict(int)\n",
        "    for doc in documents:\n",
        "        unique_words = set(doc)\n",
        "        for word in unique_words:\n",
        "            word_doc_count[word] += 1\n",
        "    # Calculate IDF for each word, avoiding division by zero\n",
        "    idfs = {word: math.log(N / float(count)) for word, count in word_doc_count.items()}\n",
        "    return idfs\n",
        "\n",
        "def calculate_tfidf(document, idfs):\n",
        "    \"\"\"\n",
        "    Calculate TF-IDF for each word in a single document based on pre-computed IDF scores.\n",
        "\n",
        "    Args:\n",
        "    document (list of str): A list of words representing a document.\n",
        "    idfs (dict): A dictionary of IDF scores pre-computed from a corpus.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary where keys are words and values are their TF-IDF scores.\n",
        "    \"\"\"\n",
        "    # Calculate TF for the given document\n",
        "    tf_scores = calculate_tf(document)\n",
        "    # Calculate TF-IDF using TF and pre-computed IDF\n",
        "    tfidf_scores = {word: tf_scores[word] * idfs.get(word, 0) for word in tf_scores}\n",
        "    return tfidf_scores\n",
        "\n",
        "def merge_sentences(document):\n",
        "    \"\"\"\n",
        "    Merge a list of sentences (where each sentence is a list of words) into a single list of words.\n",
        "\n",
        "    Args:\n",
        "    document (list of list of str): A list where each element is a sentence represented as a list of words.\n",
        "\n",
        "    Returns:\n",
        "    list of str: A merged list of words from all sentences in the document.\n",
        "    \"\"\"\n",
        "    merged_document = []\n",
        "    for sentence in document:\n",
        "        merged_document.extend(sentence)\n",
        "    return merged_document\n"
      ],
      "metadata": {
        "id": "MREdsaB3Tmwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample corpus with documents consisting of sentences\n",
        "\n",
        "corpus = [\n",
        "    [[\"the\", \"cat\", \"sat\"], [\"on\", \"the\", \"mat\"]],\n",
        "    [[\"a\", \"cat\", \"is\"], [\"sitting\", \"on\", \"the\", \"mat\"]],\n",
        "    [[\"there\", \"is\", \"a\", \"mat\"], [\"in\", \"the\", \"room\"]]\n",
        "]\n",
        "\n",
        "# Merge sentences in each document\n",
        "merged_documents = [merge_sentences(doc) for doc in corpus]\n",
        "\n",
        "# Calculate IDF scores based on all merged documents\n",
        "IDFs = calculate_idf(merged_documents)\n",
        "\n",
        "print(\"The IDF scores based on all merged documents: \")\n",
        "for key, value in IDFs.items():\n",
        "  print(f\"{key}:{value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6B258C0EcPoh",
        "outputId": "b07bdd35-3bff-49cb-9498-931feab97e4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The IDF scores based on all merged documents: \n",
            "the:0.0\n",
            "sat:1.0986122886681098\n",
            "on:0.4054651081081644\n",
            "cat:0.4054651081081644\n",
            "mat:0.0\n",
            "sitting:1.0986122886681098\n",
            "a:0.4054651081081644\n",
            "is:0.4054651081081644\n",
            "room:1.0986122886681098\n",
            "there:1.0986122886681098\n",
            "in:1.0986122886681098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gRTumKPvTbke"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}